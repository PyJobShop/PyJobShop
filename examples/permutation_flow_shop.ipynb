{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation flow shop\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/PyJobShop/PyJobShop/blob/main/examples/permutation_flow_shop.ipynb)\n",
    "\n",
    "> If you're using this notebook in Google Colab, be sure to install PyJobShop first by executing ```pip install pyjobshop``` in a cell.\n",
    "\n",
    "In this notebook, we demonstrate how to model and solve permutation flow shop problems (PFSPs) using PyJobShop. The PFSP is a scheduling environment where all jobs follow the same routing through machines and must be processed in the same sequence on all machines ([Framinan et al., 2004](https://www.tandfonline.com/doi/full/10.1057/palgrave.jors.2601784); [Kalczynski & Kamburowski, 2007](https://www.sciencedirect.com/science/article/pii/S0377221706001196); [Teixeira et al., 2025](https://www.sciencedirect.com/science/article/pii/S0377221725006149?dgcid=rss_sd_all#sec4)). Besides the classic PFSP, we will also demonstrate three of its variants: the no-idle, no-wait, and blocking PFSP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "The classic PFSP is characterized as follows:\n",
    "\n",
    "- There is a set of $n$ jobs that need to be processed on $m$ machines.\n",
    "- All jobs follow the same routing: they are processed first on machine 1, then on machine 2, and so on until machine $m$.\n",
    "- All jobs must be processed in the same sequence on all machines (permutation constraint).\n",
    "- Each job has a processing time on each machine.\n",
    "- The objective is typically to minimize the makespan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can model a PFSP using PyJobShop. For each job $j$ and each machine $k$, we define a task $T_{jk}$. We need precedence constraints to ensure that task $T_{j,k-1}$ is processed before $T_{jk}$ for $k > 1$, and sequence constraints to ensure the same job ordering on all machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for a PFSP is often given by a processing times duration matrix, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATIONS = [\n",
    "    [54, 79, 16, 66, 58],\n",
    "    [83, 3, 89, 58, 56],\n",
    "    [15, 11, 49, 31, 20],\n",
    "    [71, 99, 15, 68, 85],\n",
    "    [77, 56, 89, 78, 53],\n",
    "    [36, 70, 45, 91, 35],\n",
    "    [53, 99, 60, 13, 53],\n",
    "    [38, 60, 23, 59, 41],\n",
    "    [27, 5, 57, 49, 69],\n",
    "    [87, 56, 64, 85, 13],\n",
    "]\n",
    "\n",
    "num_jobs, num_machines = len(DURATIONS), len(DURATIONS[0])\n",
    "print(f\"Problem size: {num_jobs} jobs, {num_machines} machines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now the model the PFSP. We start by adding all jobs and machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyjobshop import Model\n",
    "\n",
    "model = Model()\n",
    "jobs = [model.add_job() for _ in range(num_jobs)]\n",
    "machines = [model.add_machine() for _ in range(num_machines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each job and machine, we create one task and its corresponding processing mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {}  # store for later\n",
    "\n",
    "for job_idx, job in enumerate(jobs):\n",
    "    for machine_idx, machine in enumerate(machines):\n",
    "        task = model.add_task(job=job)\n",
    "        tasks[job_idx, machine_idx] = task\n",
    "\n",
    "        duration = DURATIONS[job_idx][machine_idx]\n",
    "        model.add_mode(task, machine, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make sure that a job actually \"flows\" through the machine environment. This we can enforce by setting precedence constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "for job_idx in range(num_jobs):\n",
    "    for idx1, idx2 in pairwise(range(num_machines)):\n",
    "        task1 = tasks[job_idx, idx1]\n",
    "        task2 = tasks[job_idx, idx2]\n",
    "        model.add_end_before_start(task1, task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we impose the same sequence constraint, which ensures that all machines process all tasks in the same order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine1, machine2 in pairwise(machines):\n",
    "    model.add_same_sequence(machine1, machine2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now solve the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.solve(display=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyjobshop.plot import plot_machine_gantt\n",
    "\n",
    "plot_machine_gantt(result.best, model.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Notice how all jobs \"flow\" through the machine environment, and how all machines process tasks in the same sequence due to the permutation constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-idle\n",
    "\n",
    "Let's consider a variant of the PFSP with no-idle constraints ([Kalczynski and Kamburowski (2007)](https://www.sciencedirect.com/science/article/pii/S0377221706001196)). In a no-idle PFSP, each machine must process jobs consecutively without any gaps. This is required in some factories where operating machines is expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyJobShop natively supports no-idle constraints by setting the `no_idle` parameter on the `Machine` class. The model below is almost the same as above, the only difference is that we define the machines with `no_idle=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "jobs = [model.add_job() for _ in range(num_jobs)]\n",
    "machines = [model.add_machine(no_idle=True) for _ in range(num_machines)]\n",
    "tasks = {}\n",
    "\n",
    "for job_idx, job in enumerate(jobs):\n",
    "    for machine_idx, machine in enumerate(machines):\n",
    "        task = model.add_task(job=job)\n",
    "        tasks[job_idx, machine_idx] = task\n",
    "\n",
    "        duration = DURATIONS[job_idx][machine_idx]\n",
    "        model.add_mode(task, machine, duration=duration)\n",
    "\n",
    "for job_idx in range(num_jobs):\n",
    "    for idx1, idx2 in pairwise(range(num_machines)):\n",
    "        task1 = tasks[job_idx, idx1]\n",
    "        task2 = tasks[job_idx, idx2]\n",
    "        model.add_end_before_start(task1, task2)\n",
    "\n",
    "for machine1, machine2 in pairwise(machines):\n",
    "    model.add_same_sequence(machine1, machine2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.solve(display=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_machine_gantt(result.best, model.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how there are no idle times (gaps) between tasks on any machine. Due to the no-idle constraint, the makespan is slightly higher and a different sequence is chosen to optimize the schedule in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-wait\n",
    "\n",
    "Let's now consider the no-wait PFSP. In this variant, jobs cannot wait between consecutive machines. This means that once a job starts processing, it must continue through all machines without any waiting time between operations. In practice, this may be required to ensure that a product stays at a specific temperature and does not cool down between consecutive machines.\n",
    "\n",
    "We can model this using PyJobShop by ensuring that a task $T_{j,k-1}$ ends exactly when $T_{j,k}$ starts for all jobs $j$ and consecutive machines $k-1, k$. In addition, we don't need to explicitly add the same sequence constraints because the no-wait constraints naturally create a permutation schedule. This improves solving efficiency for OR-Tools CP-SAT, where sequencing constraints are computationally expensive. On the other hand, CP Optimizer benefits from adding permutation constraints -- both solvers use different techniques and have different strengths in handling constraint types. We leave them out here because PyJobShop uses OR-Tools CP-SAT by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "jobs = [model.add_job() for _ in range(num_jobs)]\n",
    "machines = [model.add_machine() for _ in range(num_machines)]\n",
    "tasks = {}\n",
    "\n",
    "for job_idx, job in enumerate(jobs):\n",
    "    for machine_idx, machine in enumerate(machines):\n",
    "        task = model.add_task(job=job)\n",
    "        tasks[job_idx, machine_idx] = task\n",
    "\n",
    "        duration = DURATIONS[job_idx][machine_idx]\n",
    "        model.add_mode(task, machine, duration=duration)\n",
    "\n",
    "for job_idx in range(num_jobs):\n",
    "    for idx1, idx2 in pairwise(range(num_machines)):\n",
    "        task1 = tasks[job_idx, idx1]\n",
    "        task2 = tasks[job_idx, idx2]\n",
    "\n",
    "        # This ensures end(task1) == start(task2).\n",
    "        model.add_end_before_start(task1, task2)\n",
    "        model.add_start_before_end(task2, task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.solve(display=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_machine_gantt(result.best, model.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no waiting time between any two consecutive tasks of the same job, and all machines naturally process jobs in the same sequence. However, the makespan is much higher than the original PFSP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking\n",
    "\n",
    "As the last example, we consider the blocking PFSP. In this case, jobs cannot wait between consecutive machines and will continue to occupy (block) the machine until the next machine becomes available. This means that once a job finishes processing on a machine, it cannot leave that machine until it can start processing on the next machine. For more details, see the paper by [Teixeira et al. (2025)](https://www.sciencedirect.com/science/article/pii/S0377221725006149?dgcid=rss_sd_all#sec4).\n",
    "\n",
    "By default, PyJobShop assumes that all tasks cannot have idle time, meaning their duration is exactly their processing time.\n",
    "To model blocking tasks, we have to allow for idle time by setting `allow_idle=True` for tasks and using the same end-at-start constraints as in the no-wait case. \n",
    "The key difference is that tasks can now extend their duration beyond the processing time if they need to block the machine while waiting for the next stage.\n",
    "\n",
    "Just like the no-wait variant, it's not required to add same sequence constraints here, because the blocking already naturally implies this constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "jobs = [model.add_job() for _ in range(num_jobs)]\n",
    "machines = [model.add_machine() for _ in range(num_machines)]\n",
    "tasks = {}\n",
    "\n",
    "for job_idx, job in enumerate(jobs):\n",
    "    for machine_idx, machine in enumerate(machines):\n",
    "        task = model.add_task(job=job, allow_idle=True)\n",
    "        tasks[job_idx, machine_idx] = task\n",
    "\n",
    "        duration = DURATIONS[job_idx][machine_idx]\n",
    "        model.add_mode(task, machine, duration=duration)\n",
    "\n",
    "for job_idx in range(num_jobs):\n",
    "    for idx1, idx2 in pairwise(range(num_machines)):\n",
    "        task1 = tasks[job_idx, idx1]\n",
    "        task2 = tasks[job_idx, idx2]\n",
    "\n",
    "        # This ensures end(task1) == start(task2).\n",
    "        model.add_end_before_start(task1, task2)\n",
    "        model.add_start_before_end(task2, task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.solve(display=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_machine_gantt(result.best, model.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit difficult to see in this figure, but we can verify the solution tasks are occupying machines longer than required by their processing time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sol_task in result.best.tasks[:10]:\n",
    "    actual = sol_task.end - sol_task.start\n",
    "    processing = model.modes[sol_task.mode].duration\n",
    "    block = actual - processing\n",
    "\n",
    "    print(f\"{actual = } | {processing = } | {block = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to model PFSP scheduling problems using PyJobShop. We showed four variants:\n",
    "\n",
    "1. **Classic PFSP**: Uses explicit `add_same_sequence` constraints to enforce identical task sequences on all machines.\n",
    "2. **No-idle PFSP**: Uses the `Machine.no_idle` parameter to eliminate machine idle time.\n",
    "3. **No-wait PFSP**: Uses no-wait constraints (`add_end_before_start` + `add_start_before_end`) which naturally create a permutation schedule without expensive sequencing constraints.\n",
    "4. **Blocking PFSP**: Combines no-wait constraints with tasks that allow idle time (tasks with `allow_idle=True`) to handle cases where tasks block machines while waiting.\n",
    "\n",
    "Each variant addresses different manufacturing constraints and demonstrates the flexibility of PyJobShop's modeling capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
